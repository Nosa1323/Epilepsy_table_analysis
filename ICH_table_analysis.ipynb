{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала нужно определить какие столбцы мы хотим загрузить из нашей таблицы. \n",
    "\n",
    "Так, для моего примера мне нужны столбцы Volume(unit)(2), SurfaceArea (um2)(5) + количество строк.\n",
    "\n",
    "Шаг1. Извлечение данных из xlsx в df, с которыми я смогу работать в python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob - показывает пути к файлам с указанным расширением и сохраняет в переменную filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import get_ipython\n",
    "get_ipython().magic('reset -sf') \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция csv_to_xlsx считывает все файлы csv в папке, затем создает xlsx для каждого файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_xlsx():\n",
    "    csv_search_string = '**/*.csv'\n",
    "    csv_filepaths = glob.glob(csv_search_string, recursive=True)\n",
    "    df = pd.DataFrame()\n",
    "    for csv in csv_filepaths:\n",
    "        out = csv.split('.')[0]+'.xlsx'\n",
    "        df = pd.read_csv(csv, sep=';', encoding='latin1',engine='python')\n",
    "        df = df.to_excel(out, float_format=\"%.4f\")\n",
    "    return (df)\n",
    "#csv_to_xlsx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "создаем пустой датафрейм, куда будут загружаться считанные столбики таблиц\n",
    "\n",
    "в цикле объединяем датафреймы из считанных файлов \n",
    "\n",
    "Нужно изменить названия столбцов,чтобы было очевидно их происхождение из другого файла. \n",
    "\n",
    "Для этого была написана функция columns_rename, где в цикле добавляется порядковый номер файла, из которого происходило извлечение\n",
    "\n",
    "\n",
    "Далее заменяем измененным названиями столбцов действующие названия в датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_extraction(search_string, N, stack_num): \n",
    "    filepaths = glob.glob(search_string, recursive=True) #можно изменять номера в N1*stack1,чтобы извлечь другие файлы\n",
    "    df = pd.DataFrame()\n",
    "    for find_files in filepaths:\n",
    "        df = df.join (pd.read_excel(find_files, usecols=[2,5]), how='outer',lsuffix=' ')\n",
    "    \n",
    "    columns_names = [j for j in df.columns.tolist()]\n",
    "\n",
    "    def columns_rename(columns_names):\n",
    "        j=1\n",
    "        for i in range (0, len(columns_names), 2):\n",
    "            columns_names[i] = 'N' + str(N) + '_stack' + str(stack_num) + '_cell' +  str(j)+ '_' + columns_names[i] #можно изменять номера в N1*stack1,чтобы отметить \n",
    "            columns_names[i+1] = 'N' + str(N) + '_stack' + str(stack_num) + '_cell' +  str(j)+ '_'  + columns_names[i+1] # принадлежность к другой партии данных\n",
    "            j+=1\n",
    "        return(columns_names)\n",
    "    df.set_axis(columns_rename(columns_names), axis=1, inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлекаем в отдельные датафреймы все файлы по стекам\n",
    "\n",
    "(?) подумать как можно оптимизировать, т.к. по всем животным будет под 50 стеков, прописывать каждый скучно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1_stack1 = file_extraction('**/N1*stack1*.xlsx', 1, 1)\n",
    "N1_stack2 = file_extraction('**/N1*stack2*.xlsx', 1, 2)\n",
    "\n",
    "N2_stack1 = file_extraction('**/N2*stack1*.xlsx', 2, 1)\n",
    "N2_stack2 = file_extraction('**/N2*stack2*.xlsx', 2, 2)\n",
    "N2_stack3 = file_extraction('**/N2*stack3*.xlsx', 2, 3)\n",
    "N2_stack4 = file_extraction('**/N2*stack4*.xlsx', 2, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на значения основных критериев описательной статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1_stack1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлекаем отдельно столбцы, анализ которых будем выполнять.\n",
    "\n",
    "(?)из-за присутствия NaN не считает перцентили (если заменить 0, могут сместиться значения исследуемых критериев). Подумать как это можно разрешить, м.б. при рассчетах можно указать использование значений >0.\n",
    "\n",
    "(?)попробовать автоматизировать создание столбиков нужного вида "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N11_cell_volume = N1_stack1.iloc[:, 0:4:2].copy()\n",
    "N11_cell_surf = N1_stack1.iloc[:, 1:4:2].copy()\n",
    "N12_cell_volume = N1_stack2.iloc[:, 0:4:2].copy()\n",
    "\n",
    "#N11_cell_volume2 = N11_cell_volume.fillna('')\n",
    "#q25, q75 = np.percentile(N11_cell_volume2.iloc[:, 0],[.25,.75])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать общую таблицу по всем животным с 2 столбиками.\n",
    "\n",
    "Для этого нужно создать какой-то цикл или функцию, извлекающие нужные столбцы и создающий на выходе датафреймы с нужными столбцами\n",
    "\n",
    "all_cell_vol = N11_cell_volume.append(N1_stack2.iloc[:, 0:4:2]) - использовать присоединения столбиков\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "не понимаю как посторить гистограмму распределения для всех столбиков(("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N1_stack1_cell1_Volume' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10960/564210673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'whitegrid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_cell_vol\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN1_stack1_cell1_Volume\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0munit\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m#all_cell_vol = pd.concat([N11_cell_volume, N12_cell_volume], ignore_index=True, sort=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#all_cell_vol = N11_cell_volume + N12_cell_volume\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'N1_stack1_cell1_Volume' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "sns.distplot(all_cell_vol(N1_stack1_cell1_Volume (unit) ) )\n",
    "#all_cell_vol = pd.concat([N11_cell_volume, N12_cell_volume], ignore_index=True, sort=False)\n",
    "#all_cell_vol = N11_cell_volume + N12_cell_volume\n",
    "#all_cell_vol.fillna(0)\n",
    "#plt.hist(all_cell_vol, bins = 4)\n",
    "#all_cell_vol[all_cell_vol > 0.01].hist(bins=10)\n",
    "all_cell_vol.columns\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919eb0904b72c37e8d6c7e3b2f7b6f162c89cafcc297fba09b2d10c79c52f5eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
